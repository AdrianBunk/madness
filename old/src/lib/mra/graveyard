	  Tensor<double> d(k,k,k);
	  double pm[k],mp[k],tmp[k];
	  double *smptr = sm->ptr();
	  double *s0ptr = s0->ptr();
	  double *spptr = sp->ptr();
	  double *dptr = d.ptr();
	  if (axis == 0) {
	    inner_result(r0, *s0, 1, axis, d);
	    for (int q=0; q<k; q++) {
	      for (int r=0; r<k; r++) {
		pm[r] = 0.0;
		mp[r] = 0.0;
	      }
	      for (int p=0; p<k; p++) {
		double rp_p = rp_right(p);
		double rm_p = rm_right(p);
		for (int r=0; r<k; r++) {
		  pm[r] += rp_p * (*sm)(p,q,r); // ??? sigh
		  mp[r] += rm_p * (*sp)(p,q,r);
		}
	      }
	      for (int p=0; p<k; p++) {
		double rp_p = rp_left(p);
		double rm_p = rm_left(p);
		for (int r=0; r<k; r++) {
		  d(p,q,r) += pm[r]*rp_p + mp[r]*rm_p;
		}
	      }
	    }
	  }
	  else if (axis == 1) {
	    for (int p=0; p<k; p++) {
	      for (int r=0; r<k; r++) {
		pm[r] = 0.0;
		mp[r] = 0.0;
	      }
	      for (int s=0; s<k; s++) {
		double rp_s = rp_right(s);
		double rm_s = rm_right(s);
		for (int r=0; r<k; r++) {
		  pm[r] += rp_s * *smptr++;
		  mp[r] += rm_s * *spptr++;
		}
	      }
	      for (int q=0; q<k; q++) {
		for (int r=0; r<k; r++) {
		  tmp[r] = 0.0;
		}
		double *s0_psr = s0ptr;
		for (int s=0; s<k; s++) {
		  double r0qs = r0(q,s);
		  for (int r=0; r<k; r++) {
		    tmp[r] += r0qs * *s0_psr++;
		  }
		}
		double rpq = rp_left(q);
		double rmq = rm_left(q);
		for (int r=0; r<k; r++) {
		  *dptr++ = tmp[r] + pm[r]*rpq + mp[r]*rmq;
		}
	      }
	      s0ptr += k*k;
	    }
	  }
	  else {
	    inner_result(*s0, r0, 2, 1, d);
	    for (int p=0; p<k; p++) {
	      for (int q=0; q<k; q++) {
		double pm = 0.0;
		double mp = 0.0;
		for (int r=0; r<k; r++) {
		  pm += rp_right(r)* *smptr++;
		  mp += rm_right(r)* *spptr++;
		}
		for (int r=0; r<k; r++) {
		  *dptr++ += pm*rp_left(r) + mp*rm_left(r);
		}
	      }
	    }
	  }






//     template <class T>
//     void Function<T>::_refine_scale_projection(OctTreeT* coeff) {
//         if (have data) {
//             if (needs refining) {
//                 clean up old coeffs;
//                 FORIJK(c = insert child;
//                        if (c) {
//                            if (c->islocal()) {
//                                project(c);
//                                refine(c);
//                            }
//                            else 
//                                send msg to owner of c;
//                        }
//                        );
//             }
//         }
//         else { // don't have data
//             if (coeff->islocal()) {
//                 FORIJK(if (child) refine(c););
//             }
//             else {
//                 // This node is remote.  It is either the remote parent
//                 // of the local subtree, or an existing remote child.
//                 if (remote parent) {
//                     loop thru local children;
//                     if (
//         }
//     }
//         Tensor<T> d = filter(coeff->data());
//         d(data->s0) = 0.0;
//         double dnorm = d.normf();
//         if (dnorm > truncate_threshold(coeff->n())) {
//             if (coeff->n() < max_refine_level) {
//                 FORIJK(_fine_scale_projection(s->child(i,j,k),initial_level););
//             }
//             else {
//                     nterminated++;
//             }
//         }

    /// Private:  Projects function in given box
    template <class T>
    void Function<T>::_project(OctTreeT* tree) {
        // We are at level n in the of wavelet coefficients, which
        // corresponds to level n+1 in the scaling function
        // coefficients.  Evaluate all 8 blocks of the scaling
        // function coefficients which are stored together in the tree.
        int npt = data->npt;
        Tensor<T> r(2*k,2*k,2*k);
        Tensor<T> fval(npt,npt,npt); 
        Level n = tree->n();
        Translation x=2*tree->x(), y=2*tree->y(), z=2*tree->z();
        Slice* s = data->s;
        for (int ix=0; ix<2; ix++) {
            for (int iy=0; iy<2; iy++) {
                for (int iz=0; iz<2; iz++) {
                    if (data->vf) {
                        _vfcube(n+1, x+ix, y+iy, z+iz, data->vf, fval);
                    }
                    else if (data->f) {
                        _fcube(n+1, x+ix, y+iy, z+iz, data->f, fval);
                    }
                    // Can optimize away the tensor construction in transform3d
                    r(s[ix],s[iy],s[iz]) = transform3d(fval,data->quad_phiw);
                }
            }
        }
        tree->set_data(r.scale(pow(0.125,0.5*n)));
    }
    
    /// Private:  Projects function at given level.  No communication.

    /// It is assumed that this is being done to an initially zero Function
    /// by _init immediately after construction
    template <class T>
    void Function<T>::_fine_scale_projection(OctTreeT* coeff, Level initial_level) {
        // Recur down oct_tree to initial_level, filling above with empty
        // cells.  Project when get to desired level

        if (coeff->n() < initial_level) {
            FORIJK(OctTreeT* c = coeff->insert_child(i,j,k);
                   if (c) _fine_scale_projection(c,initial_level););
        }
        else if (coeff->n()==initial_level && coeff->islocal()) {
            _project(coeff);
            cout << "projected "; coeff->print_coords(); 
            cout << " " << coeff->data().normf() << endl;
        }
    }





        TensorT* at = afun.coeff(tree);
        TensorT* bt = bfun.coeff(tree);

        if (at && bt) {
            TensorT atmp(k,k,k), btmp(k,k,k), r(2*k,2*k,2*k);
            Slice* s = data->cdata->s;
            FORIJK(atmp(___) = at(s[i],s[j],s[k]);
                   transform3d_inplace(atmp, 
                                       data->cdata->quad_phit, 
                                       data->cdata->work);
                   btmp(___) = bt(s[i],s[j],s[k]);
                   transform3d_inplace(btmp, 
                                       data->cdata->quad_phit, 
                                       data->cdata->work);
                   r(s[i],s[j],s[k]) = transform3d_inplace(atmp.emul(btmp),
                                                           data->cdata->quad_phiw,
                                                           data->cdata->work);
                   );
            double scale = pow(8.0,0.5*r->n());
            cfun->set_coeff(tree,r.scale(scale));
            return;
        }
        else if (at) {
            TensorT atmp(k,k,k);
            Slice* s = data->cdata->s;
            // refine a down & copy down
            
            // if children are remote send, else recur
        }
        else if (bt) {
            // refine b down
            // if children are remote send, else recur
        }
        else {
            // both
            // recur down
        }








            if (coeff(tree)) {

            } else if (tree->islocalsubtreeparent() && isremote(tree)) {
                
        	int nactivekids = 0;
        	FOREACH_ACTIVE_CHILD(OctTreeT, tree,
        						 nactivekids++;
        						 if (child->islocal()) _autorefine(child););	
        						 		

 			} else if (tree->isremote() && nactivekids==0) {
 				// Remote parent has data and may have refined 
 				bool refined;
                print("AA waiting for refined from",tree->rank(), tree->n(),tree->x(),tree->y(),tree->z());
 				comm()->Recv(refined, tree->rank(), 99);
                print("AA got refined");
 				if (refined) {
 					const Slice& s0 = data->cdata->s[0];
                	Tensor<T>& work1 = data->cdata->work1;
                	long k2 = k*2;
 					FOREACH_CHILD(OctTreeT, tree,
                              print("AA waiting for data from",tree->rank());
 							  comm()->Recv(work1.ptr(), work1.size, tree->rank(), 66);
                              print("AA got data from",tree->rank());
                              Tensor<T>*c = set_coeff(child, Tensor<T>(k2, k2, k2));
                              (*c)(s0, s0, s0) = work1;
                              unfilter_inplace(*c); // sonly needed!
 					);
 				}
 			}
        };

// for just trading two trees around and then putting them back

int me = comm.rank();
std::vector< SharedPtr< OctTree< FunctionNode> > > treeList;
OctTree<FunctionNode> *otfn = new OctTree<FunctionNode> ();
OctTree<FunctionNode> *otfn2 = new OctTree<FunctionNode> ();
if (me == 0)
{
    archive::MPIOutputArchive arsend(comm, 1);
    archive::MPIInputArchive arrecv(comm, 1);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn;
    std::cout << "otfn depthFirstTraverse:" << std::endl;
    otfn->depthFirstTraverseAll();
    std::cout << "end otfn depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> >  (otfn));
    FunctionDefaults::tree->setTreeList(treeList);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn2;
    std::cout << "otfn2 depthFirstTraverse:" << std::endl;
    otfn2->depthFirstTraverseAll();
    std::cout << "end otfn2 depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> >  (otfn2));
    FunctionDefaults::tree->setTreeList(treeList);
}
else if (me == 1)
{
    archive::MPIOutputArchive arsend(comm, 0);
    archive::MPIInputArchive arrecv(comm, 0);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn;
    std::cout << "otfn depthFirstTraverse:" << std::endl;
    otfn->depthFirstTraverseAll();
    std::cout << "end otfn depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> >  (otfn));
    FunctionDefaults::tree->setTreeList(treeList);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn2;
    std::cout << "otfn2 depthFirstTraverse:" << std::endl;
    otfn2->depthFirstTraverseAll();
    std::cout << "end otfn2 depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> > (otfn2));
    FunctionDefaults::tree->setTreeList(treeList);
}


/*
    template <typename T>
    class MulNodeInfo {
    public:
        const Tensor<T>* t;
        Level n;
        Translation lx, ly, lz;
        bool status;

        MulNodeInfo()
            : t(0),n(0),lx(0),ly(0),lz(0),status(false) {}

        void set(const Tensor<T>* t, Level n,
                 Translation lx, Translation ly, Translation lz) {
            this->t = t;
            this->n = n;
            this->lx = lx;
            this->ly = ly;
            this->lz = lz;
            status = true;
        template <typename T>
        class MulNodeInfo {
        public:
            const Tensor<T>* t;
            Level n;
            Translation lx, ly, lz;
            bool status;
     
            MulNodeInfo()
                : t(0),n(0),lx(0),ly(0),lz(0),status(false) {}
     
            void set(const Tensor<T>* t, Level n,
                     Translation lx, Translation ly, Translation lz) {
                this->t = t;
                this->n = n;
                this->lx = lx;
                this->ly = ly;
                this->lz = lz;
                status = true;
            };
     
            operator bool() {return status;};
     
            void send(Process rank);
     
            void recv(Process rank);
>>>>>>> .r80
        };
     
        /// At the quadrature points for box (n,l) evaluate the scaling functions (nn,ll)
        template <typename T>
        Tensor<double> Function<T>::mul_eval_sf(Level n, Translation l, Level nn, Translation ll) {
            int npt = data->cdata->npt;
            Tensor<double> phi(npt,k); // phi(i,j) = at  value of phi[j](x[i])
     
            Tensor<double>& quad_x = data->cdata->quad_x;
     
            double scale = 1.0/two_to_power(n);
            double fac = sqrt(double(two_to_power(nn)));
            if (n < nn) throw "mul_eval_sf: n < nn ?";
            double twonn = two_to_power(n-nn);
            double xlo = l - twonn*ll;
            for (int i=0; i<npt; i++) {
                double p[200];
                double x = scale*(xlo + quad_x(i));
                legendre_scaling_functions(x,k,p);
                for (int j=0; j<k; j++) {
                    phi(i,j) = phi[j]*fac
                }
            }
        }
     
        template <typename T>
        T Function<T>::_mul(Function<T>& afun, Function<T>& bfun,
                            Function<T>& cfun, OctTreeT* tree, 
                            MulNodeInfo<T>& ainfo, MulNodeInfo<T>& binfo) {
            cfun.set_active(tree);
     
            if (tree->isremote()) {
                if (tree->islocalsubtreeparent()) {
                    // If a function is locally labelled active, then the
                    // coefficients are somewhere below this parent node
                    // (perhaps remote).  If a function is inactive, then
                    // the coefficients must be above and we need to
                    // receive them.
                    if (!afun.isactive()) ainfo.recv(tree->rank());
                    if (!bfun.isactive()) binfo.recv(tree->rank());
                }
                else {
                    if (ainfo) ainfo.send(tree->rank());
                    if (binfo) binfo.send(tree->rank());
                    return;
                }
            }
     
            if (at) ainfo.set(at, tree->n(), tree->lx(), tree->ly(), tree->lz());
            if (bt) binfo.set(at, tree->n(), tree->lx(), tree->ly(), tree->lz());
            if (ainfo && binfo) {
                TensorT r(2*k,2*k,2*k);
                // All of the tensor constructors can be optimized away
                // with just a little work.
                FORIJKL(Level n = tree->n()+1;
                        Translation lx = tree->x()*2+i;
                        Translation ly = tree->y()*2+j;
                        Translation lz = tree->z()*2+k;
                        Tensor<double> aphix = mul_eval_sf(n,lx,a.n,a.lx);
                        Tensor<double> aphiy = mul_eval_sf(n,ly,a.n,a.ly);
                        Tensor<double> aphiz = mul_eval_sf(n,lz,a.n,a.lz);
                        Tensor<double> bphix = mul_eval_sf(n,lx,b.n,b.lx);
                        Tensor<double> bphiy = mul_eval_sf(n,ly,b.n,b.ly);
                        Tensor<double> bphiz = mul_eval_sf(n,lz,b.n,b.lz);
                        
                        TensorT aval = transform3d_3c(*ainfo.t,aphix,aphiy,aphiz);
                        TensorT bval = transform3d_3c(*binfo.t,bphix,bphiy,bphiz);
                        r(s[i],s[j],s[k]) = transform3d_inplace(aval.emul(bval),
                                                                data->cdata->quad_phiw,
                                                                data->cdata->work);
                        );
            }
            else {
                FOREACH_CHILD(OctTreeT, tree,
                              if (afun.isactive(child) || bfun.isactive(child)) {
                                  _mul(afun,bfun,cfun,child,ainfo,binfo);
                              });
            }
        }
    */
    
    

        /// Fill in missing local nodes down to specified location
        void fill_in_local_tree(Level n, Translation x, Translation y, Translation z) {
            OctTreeTPtr p = tree();
            MADNESS_ASSERT(p);
            while (p->n() < n) {
                if (p->isremote()) MADNESS_EXCEPTION("Function: fill_in_local_tree: remote?",0);
                // All children must exist
                FORIJK(if (!p->child(i,j,k)) p->insert_local_child(i,j,k););
                long nn = p->n() - n - 1;
                long xx = (x>>nn)&1;
                long yy = (y>>nn)&1;
                long zz = (z>>nn)&1;    
                p = p->child(xx,yy,zz);
            }
        };
        
        
        
        
            template <typename T>
    void Function<T>::_compress(OctTreeTPtr& tree) {
        FOREACH_CHILD(OctTreeTPtr, tree,
                      if (isactive(child)) _compress(child););

        if (isremote(tree)) {
            long k3 = k*k*k;
            if (tree->islocalsubtreeparent()) {
                // Send data from active children to remote parent
                std::vector<Slice>& s0 = data->cdata->s0;
                TensorT& buf = data->cdata->work1;
                FOREACH_CHILD(OctTreeTPtr, tree,
                              if (isactive(child)) {
                              const TensorT* c = coeff(child);
                                  if (!c) throw "compress: yo! show me the data(2)!";
                                  buf(s0) = (*c)(s0);
              //                                  print("compress: sending",buf.normf(),"to",tree->rank());
                                  comm()->Send(buf.ptr(), k3, tree->rank(), COMPRESS_TAG);
              //                                  print("child norm before",c->normf());
                                  (*c)(s0) = T(0.0);
              //                                  print("child norm after",c->normf());
                              }
                             );
            } else {
                // Receive data from a remote child and store as
                // ghost ... parent will eventually delete it.
                TensorT* t = set_coeff(tree,TensorT(k,k,k));
                comm()->Recv(t->ptr(), k3, tree->rank(), COMPRESS_TAG);
//                print("compress: received",t->normf(),"from",tree->rank());
            }
        } else {
            // Node is local.  May or may not have data.
            Slice *s = data->cdata->s;
            TensorT* t = coeff(tree);
            if (!t) t = set_coeff(tree,TensorT(2*k,2*k,2*k));
            FOREACH_CHILD(OctTreeTPtr, tree,
                          if (isactive(child)) {
                          TensorT* c = coeff(child);
                              if (!c) throw "compress: yo! show me the data!";
                              (*t)(s[i],s[j],s[k]) += (*c)(s[0],s[0],s[0]);
                              if (isremote(child)) {
                                  unset_coeff(child);
                              } else {
                                  (*c)(s[0],s[0],s[0]) = T(0.0);
                              }
                          }
                         );
            //set_coeff(tree,filter(*t));
            filter_inplace(*t);
        }
    }
    
        template <typename T>
    void Function<T>::_truncate(double tol, OctTreeTPtr& tree){
      int nactive_child = 0;
      
      FOREACH_LOCAL_CHILD(OctTreeTPtr, tree, 
                          if (isactive(child)) _truncate(tol, child);
                          if (isactive(child)) nactive_child++;);          
      FOREACH_REMOTE_CHILD(OctTreeTPtr, tree,
                           if (isactive(child)) {
                               bool active;
                               comm()->Recv(active, child->rank(), TRUNCATE_TAG1);
                               if (active) nactive_child++;
                               else set_inactive(child);
                           }); 

     if (!coeff(tree)) {
         // This is the active remote parent of the local subtree.  If I have an
         // active child then I know the remote parent will not truncate.
         // But if I don't have any active children I must be told the decision.
         if (nactive_child == 0) {
            bool active;
            comm()->Recv(active,tree->rank(),TRUNCATE_TAG2);
            if (!active) set_inactive(tree);
          }
          return;
      }
      
      // If I have no active children then I can try to truncate
      if (nactive_child == 0 && 
          coeff(tree)->normf() < truncate_tol(tol,tree->n())) {
          //print("TT truncating",tree->n(),tree->x(),tree->y(),tree->z(),coeff(tree)->normf());
          unset_coeff(tree);
          set_inactive(tree);
      }
                        
      // Notify any remote clones with only inactive children of my possibly 
      // changed active status.
      ProcessID ranks[8];
      int np = tree->unique_child_procs(ranks);
      for (int p=0; p<np; p++) {
           int n=0;
           FOREACH_REMOTE_CHILD(OctTreeTPtr, tree, 
                                if (isactive(child) && child->rank()==ranks[p]) n++;);
           if (n==0) comm()->Send(isactive(tree), ranks[p], TRUNCATE_TAG2);
       }
            
      // Notify any remote parent of my possibly changed active status.
      if (tree->parent() && tree->parent()->isremote()) 
          comm()->Send(isactive(tree), tree->parent()->rank(), TRUNCATE_TAG1);
    };
    
    
        template <typename T>
    void Function<T>::_autorefine(OctTreeTPtr& tree) {
        MADNESS_ASSERT(tree);
        bool msg[2], refine=false;
        const Slice* s = data->cdata->s;
        const Slice& s0 = s[0];
        long k2 = k*2;
        Tensor<T>& work1 = data->cdata->work1;
        
        if (islocal(tree)) {
            ProcessID ranks[8];
            int np = tree->unique_child_procs(ranks);
            if (coeff(tree)) { // Test for refinement
                double tol = truncate_tol(data->thresh,tree->n()+1);
                const Tensor<T>& c = *coeff(tree);
                double lo,hi;
                FORIJK(_tnorms(c(s[i],s[j],s[k]),&lo,&hi);
                       refine = hi > tol;
                       if (refine) goto done;);
                done:;
            }

            // Tell remote clones what is going on
            msg[0] = isactive(tree); 
            msg[1] = refine;
            
            for (int i=0; i<np; i++) comm()->Send(msg,2,ranks[i],AUTOREF_TAG1);
            
            if (refine) { // refine, sending data as necessary;
                const Tensor<T>& c = *coeff(tree);
                FORIJK(OctTreeTPtr child = tree->child(i,j,k);
                       if (!child) child = tree->insert_local_child(i,j,k);
                       set_active(child);
                       if (child->islocal()) {
                          Tensor<T>*t = set_coeff(child, Tensor<T>(k2, k2, k2));
                          (*t)(s0, s0, s0) = c(s[i],s[j],s[k]);
                          unfilter_inplace(*t);  // sonly!
                       }
                       else {
                          work1(s0,s0,s0) = c(s[i],s[j],s[k]); // contig. copy
                          comm()->Send(work1.ptr(), work1.size, child->rank(), AUTOREF_TAG2);
                       }
                    );
                unset_coeff(tree);               
            }
        } else if (isremote(tree) && tree->islocalsubtreeparent()) {
            comm()->Recv(msg,2,tree->rank(),AUTOREF_TAG1);
            bool active=msg[0], refine=msg[1];
            if (!active && isactive(tree)) {
                MADNESS_EXCEPTION("Remote clone thinks it is inactive but I think I am active",0);
            } else if (active) {
                set_active(tree);
                if (refine) {
                    FORIJK(OctTreeTPtr child = tree->child(i,j,k);
                          if (!child) child = tree->insert_local_child(i,j,k);
                          set_active(child);
                          comm()->Recv(work1.ptr(), work1.size, tree->rank(), AUTOREF_TAG2);
                          Tensor<T>*c = set_coeff(child, Tensor<T>(k2, k2, k2));
                          (*c)(s0, s0, s0) = work1;
                          unfilter_inplace(*c); // sonly needed!
                    );
                }
            }
        }            
        FOREACH_CHILD(OctTreeTPtr, tree, if (islocal(child)) _autorefine(child););    
    };

    template <typename T>
    void Function<T>::_square(OctTreeTPtr& tree) {
         MADNESS_ASSERT(tree);
         FOREACH_ACTIVE_CHILD(OctTreeTPtr, tree, _square(child););

         if (coeff(tree)) {
            Tensor<T>& t = *coeff(tree);
            Tensor<T> r(k, k, k);
            const Slice* s = data->cdata->s;
            double scale = std::pow(8.0, 0.5 * (tree->n()+1));
            FORIJK(r(___) = t(s[i], s[j], s[k]);
                   transform3d_inplace(r, data->cdata->quad_phit,
                                       data->cdata->work1);
                   r.emul(r).scale(scale);
                   transform3d_inplace(r, data->cdata->quad_phiw,
                                       data->cdata->work1);
                   t(s[i], s[j], s[k]) = r;
                  );
         }
    };
    
    
    template <typename T>
    void Function<T>::_recur_coeff_down(OctTreeT* tree, bool keep) {
        // 1,1,1 since this is the last entry that would be made
        // ensuring that all others are there also.
        if (tree->child(1,1,1) && isactive(tree->child(1,1,1))) {
            // This node has already been recurred down ... skip it.
            return;
        }
        
        if (tree->n() >= data->max_refine_level) 
            MADNESS_EXCEPTION("recur_coeff_down: exceeding max refine level",tree->n());
        
        // sonly on unfilter is a 3x optimization in 3d ... we need it!
        const Tensor<T>& c = *coeff(tree);
        long k2 = k*2;
        const std::vector<Slice>& s0 = data->cdata->s0;
        const Slice* s = data->cdata->s;
        FORIJK(OctTreeTPtr child = tree->child(i,j,k);
               if (!child) child = tree->insert_local_child(i,j,k);
               set_active(child);
               // If we are keeping the parent, the child will eventually be autocleaned
               set_acflag(child,keep);
               Tensor<T>*t = set_coeff(child, Tensor<T>(k2, k2, k2));
               (*t)(s0) = c(s[i],s[j],s[k]);
               unfilter_inplace(*t);  // sonly!
               //madness::print(child->n(),child->x(),child->y(),child->z(),"recurring");
               );
        if (!keep) unset_coeff(tree);
    }
    
    template <typename T>
    const Tensor<T>* Function<T>::_get_scaling_coeffs(OctTreeTPtr& t, int axis, int inc) {
        //madness::print("getting",t->n(),t->x(),t->y(),t->z());

        long xyz[3] = {t->x(), t->y(), t->z()};
        xyz[axis] += inc;
        long x=xyz[0], y=xyz[1], z=xyz[2];
        
        // Enforce boundary conditions (here use zero for external values)
        if (xyz[axis] < 0 || ((unsigned long) xyz[axis]) >= two_to_power(t->n())) return &data->cdata->zero_tensor;
        
        // Find node or its parent in the tree.
        OctTreeT* p = t->find(t->n(),x, y, z);
        // If not active, find the lowest active parent
        while (p && !isactive(p)) p = p->parent();

        if (! p) MADNESS_EXCEPTION("get_scaling_coeffs: failed to find parent?",0);
        if (! coeff(p)) return 0; //  The parent does not have data ... it is below.

        // Recur data down from parent to desired level.  Note, need to introduce
        // additional checking and mutex when we start running multithreaded. 
        while(p->n() < t->n()) {
            // MUTEX 
            // check again that someone else has not already made it
            _recur_coeff_down(p,true);
            // END MUTEX
            long nn = t->n() - p->n() - 1;
            long xx = (x>>nn)&1;
            long yy = (y>>nn)&1;
            long zz = (z>>nn)&1;
            p = p->child(xx,yy,zz).get();
        }

        return coeff(p);
    }
   
    
    template <typename T>
    void Function<T>::_dodiff(Function<T>& df, OctTreeTPtr& tree, int axis) {
        //madness::print("dodiff",tree->n(),tree->x(),tree->y(),tree->z());

        // This routine is applied at each leaf node ... i.e., where we have data in tree.
        df.set_active(tree);
        const TensorT* t0 = coeff(tree);
        const TensorT* tm = _get_scaling_coeffs(tree,axis,-1);
        const TensorT* tp = _get_scaling_coeffs(tree,axis, 1);
        if (tm && tp) {
            _dodiff_kernel(df, tree, axis, *t0, *tm, *tp);
        }
        else {
            _recur_coeff_down(tree.get(),true);
            FOREACH_CHILD(OctTreeTPtr, tree, _dodiff(df, child, axis);); 
        }          
    };
    
    

    template <typename T>
    void Function<T>::_reconstruct(OctTreeTPtr& tree) {
        std::vector<Slice>& s0 = data->cdata->s0;
        Slice* s = data->cdata->s;
        TensorT& buf = data->cdata->work1;
        long k3 = k*k*k;

        if (isremote(tree)) {
            if (tree->islocalsubtreeparent()) {
                FOREACH_CHILD(OctTreeTPtr, tree,
                              if (isactive(child)) {
                              comm()->Recv(buf.ptr(),k3,tree->rank(),RECONSTRUCT_TAG);
              //                                  print("reconstruct: received",buf.normf(),"from",tree->rank());
                                  (*coeff(child))(s0) = buf;
                              }
                             );
            } else {
                throw "_reconstruct: should not be here?";
            }
        } else {
            int nchild = 0;
            TensorT* t = coeff(tree);
            unfilter_inplace(*t);
            FOREACH_CHILD(OctTreeTPtr, tree,
                          if (isactive(child)) {
                          nchild++;
                          if (islocal(child)) {
                                  (*coeff(child))(s0) = (*t)(s[i],s[j],s[k]);
                              } else {
                                  buf(s0) = (*t)(s[i],s[j],s[k]);
              //                                  print("reconstruct: sending",buf.normf(),"to",child->rank());
                                  comm()->Send(buf.ptr(),k3,child->rank(),RECONSTRUCT_TAG);
                              }
                          }
                         );
            if (nchild) unset_coeff(tree); // NEED TO KEEP IF WANT REDUNDANT TREE
        }

        FOREACH_CHILD(OctTreeTPtr, tree,
                      if (isactive(child) && islocal(child)) _reconstruct(child););
    }
    



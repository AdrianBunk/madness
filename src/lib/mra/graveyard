	  Tensor<double> d(k,k,k);
	  double pm[k],mp[k],tmp[k];
	  double *smptr = sm->ptr();
	  double *s0ptr = s0->ptr();
	  double *spptr = sp->ptr();
	  double *dptr = d.ptr();
	  if (axis == 0) {
	    inner_result(r0, *s0, 1, axis, d);
	    for (int q=0; q<k; q++) {
	      for (int r=0; r<k; r++) {
		pm[r] = 0.0;
		mp[r] = 0.0;
	      }
	      for (int p=0; p<k; p++) {
		double rp_p = rp_right(p);
		double rm_p = rm_right(p);
		for (int r=0; r<k; r++) {
		  pm[r] += rp_p * (*sm)(p,q,r); // ??? sigh
		  mp[r] += rm_p * (*sp)(p,q,r);
		}
	      }
	      for (int p=0; p<k; p++) {
		double rp_p = rp_left(p);
		double rm_p = rm_left(p);
		for (int r=0; r<k; r++) {
		  d(p,q,r) += pm[r]*rp_p + mp[r]*rm_p;
		}
	      }
	    }
	  }
	  else if (axis == 1) {
	    for (int p=0; p<k; p++) {
	      for (int r=0; r<k; r++) {
		pm[r] = 0.0;
		mp[r] = 0.0;
	      }
	      for (int s=0; s<k; s++) {
		double rp_s = rp_right(s);
		double rm_s = rm_right(s);
		for (int r=0; r<k; r++) {
		  pm[r] += rp_s * *smptr++;
		  mp[r] += rm_s * *spptr++;
		}
	      }
	      for (int q=0; q<k; q++) {
		for (int r=0; r<k; r++) {
		  tmp[r] = 0.0;
		}
		double *s0_psr = s0ptr;
		for (int s=0; s<k; s++) {
		  double r0qs = r0(q,s);
		  for (int r=0; r<k; r++) {
		    tmp[r] += r0qs * *s0_psr++;
		  }
		}
		double rpq = rp_left(q);
		double rmq = rm_left(q);
		for (int r=0; r<k; r++) {
		  *dptr++ = tmp[r] + pm[r]*rpq + mp[r]*rmq;
		}
	      }
	      s0ptr += k*k;
	    }
	  }
	  else {
	    inner_result(*s0, r0, 2, 1, d);
	    for (int p=0; p<k; p++) {
	      for (int q=0; q<k; q++) {
		double pm = 0.0;
		double mp = 0.0;
		for (int r=0; r<k; r++) {
		  pm += rp_right(r)* *smptr++;
		  mp += rm_right(r)* *spptr++;
		}
		for (int r=0; r<k; r++) {
		  *dptr++ += pm*rp_left(r) + mp*rm_left(r);
		}
	      }
	    }
	  }






//     template <class T>
//     void Function<T>::_refine_scale_projection(OctTreeT* coeff) {
//         if (have data) {
//             if (needs refining) {
//                 clean up old coeffs;
//                 FORIJK(c = insert child;
//                        if (c) {
//                            if (c->islocal()) {
//                                project(c);
//                                refine(c);
//                            }
//                            else 
//                                send msg to owner of c;
//                        }
//                        );
//             }
//         }
//         else { // don't have data
//             if (coeff->islocal()) {
//                 FORIJK(if (child) refine(c););
//             }
//             else {
//                 // This node is remote.  It is either the remote parent
//                 // of the local subtree, or an existing remote child.
//                 if (remote parent) {
//                     loop thru local children;
//                     if (
//         }
//     }
//         Tensor<T> d = filter(coeff->data());
//         d(data->s0) = 0.0;
//         double dnorm = d.normf();
//         if (dnorm > truncate_threshold(coeff->n())) {
//             if (coeff->n() < max_refine_level) {
//                 FORIJK(_fine_scale_projection(s->child(i,j,k),initial_level););
//             }
//             else {
//                     nterminated++;
//             }
//         }

    /// Private:  Projects function in given box
    template <class T>
    void Function<T>::_project(OctTreeT* tree) {
        // We are at level n in the of wavelet coefficients, which
        // corresponds to level n+1 in the scaling function
        // coefficients.  Evaluate all 8 blocks of the scaling
        // function coefficients which are stored together in the tree.
        int npt = data->npt;
        Tensor<T> r(2*k,2*k,2*k);
        Tensor<T> fval(npt,npt,npt); 
        Level n = tree->n();
        Translation x=2*tree->x(), y=2*tree->y(), z=2*tree->z();
        Slice* s = data->s;
        for (int ix=0; ix<2; ix++) {
            for (int iy=0; iy<2; iy++) {
                for (int iz=0; iz<2; iz++) {
                    if (data->vf) {
                        _vfcube(n+1, x+ix, y+iy, z+iz, data->vf, fval);
                    }
                    else if (data->f) {
                        _fcube(n+1, x+ix, y+iy, z+iz, data->f, fval);
                    }
                    // Can optimize away the tensor construction in transform3d
                    r(s[ix],s[iy],s[iz]) = transform3d(fval,data->quad_phiw);
                }
            }
        }
        tree->set_data(r.scale(pow(0.125,0.5*n)));
    }
    
    /// Private:  Projects function at given level.  No communication.

    /// It is assumed that this is being done to an initially zero Function
    /// by _init immediately after construction
    template <class T>
    void Function<T>::_fine_scale_projection(OctTreeT* coeff, Level initial_level) {
        // Recur down oct_tree to initial_level, filling above with empty
        // cells.  Project when get to desired level

        if (coeff->n() < initial_level) {
            FORIJK(OctTreeT* c = coeff->insert_child(i,j,k);
                   if (c) _fine_scale_projection(c,initial_level););
        }
        else if (coeff->n()==initial_level && coeff->islocal()) {
            _project(coeff);
            cout << "projected "; coeff->print_coords(); 
            cout << " " << coeff->data().normf() << endl;
        }
    }





        TensorT* at = afun.coeff(tree);
        TensorT* bt = bfun.coeff(tree);

        if (at && bt) {
            TensorT atmp(k,k,k), btmp(k,k,k), r(2*k,2*k,2*k);
            Slice* s = data->cdata->s;
            FORIJK(atmp(___) = at(s[i],s[j],s[k]);
                   transform3d_inplace(atmp, 
                                       data->cdata->quad_phit, 
                                       data->cdata->work);
                   btmp(___) = bt(s[i],s[j],s[k]);
                   transform3d_inplace(btmp, 
                                       data->cdata->quad_phit, 
                                       data->cdata->work);
                   r(s[i],s[j],s[k]) = transform3d_inplace(atmp.emul(btmp),
                                                           data->cdata->quad_phiw,
                                                           data->cdata->work);
                   );
            double scale = pow(8.0,0.5*r->n());
            cfun->set_coeff(tree,r.scale(scale));
            return;
        }
        else if (at) {
            TensorT atmp(k,k,k);
            Slice* s = data->cdata->s;
            // refine a down & copy down
            
            // if children are remote send, else recur
        }
        else if (bt) {
            // refine b down
            // if children are remote send, else recur
        }
        else {
            // both
            // recur down
        }








            if (coeff(tree)) {

            } else if (tree->islocalsubtreeparent() && isremote(tree)) {
                
        	int nactivekids = 0;
        	FOREACH_ACTIVE_CHILD(OctTreeT, tree,
        						 nactivekids++;
        						 if (child->islocal()) _autorefine(child););	
        						 		

 			} else if (tree->isremote() && nactivekids==0) {
 				// Remote parent has data and may have refined 
 				bool refined;
                print("AA waiting for refined from",tree->rank(), tree->n(),tree->x(),tree->y(),tree->z());
 				comm()->Recv(refined, tree->rank(), 99);
                print("AA got refined");
 				if (refined) {
 					const Slice& s0 = data->cdata->s[0];
                	Tensor<T>& work1 = data->cdata->work1;
                	long k2 = k*2;
 					FOREACH_CHILD(OctTreeT, tree,
                              print("AA waiting for data from",tree->rank());
 							  comm()->Recv(work1.ptr(), work1.size, tree->rank(), 66);
                              print("AA got data from",tree->rank());
                              Tensor<T>*c = set_coeff(child, Tensor<T>(k2, k2, k2));
                              (*c)(s0, s0, s0) = work1;
                              unfilter_inplace(*c); // sonly needed!
 					);
 				}
 			}
        };

// for just trading two trees around and then putting them back

int me = comm.rank();
std::vector< SharedPtr< OctTree< FunctionNode> > > treeList;
OctTree<FunctionNode> *otfn = new OctTree<FunctionNode> ();
OctTree<FunctionNode> *otfn2 = new OctTree<FunctionNode> ();
if (me == 0)
{
    archive::MPIOutputArchive arsend(comm, 1);
    archive::MPIInputArchive arrecv(comm, 1);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn;
    std::cout << "otfn depthFirstTraverse:" << std::endl;
    otfn->depthFirstTraverseAll();
    std::cout << "end otfn depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> >  (otfn));
    FunctionDefaults::tree->setTreeList(treeList);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn2;
    std::cout << "otfn2 depthFirstTraverse:" << std::endl;
    otfn2->depthFirstTraverseAll();
    std::cout << "end otfn2 depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> >  (otfn2));
    FunctionDefaults::tree->setTreeList(treeList);
}
else if (me == 1)
{
    archive::MPIOutputArchive arsend(comm, 0);
    archive::MPIInputArchive arrecv(comm, 0);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn;
    std::cout << "otfn depthFirstTraverse:" << std::endl;
    otfn->depthFirstTraverseAll();
    std::cout << "end otfn depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> >  (otfn));
    FunctionDefaults::tree->setTreeList(treeList);
    arsend & *(FunctionDefaults::tree->tree(0).get());
    arrecv & *otfn2;
    std::cout << "otfn2 depthFirstTraverse:" << std::endl;
    otfn2->depthFirstTraverseAll();
    std::cout << "end otfn2 depthFirstTraverse" << std::endl;
    treeList.clear();
    treeList.push_back(SharedPtr<OctTree<FunctionNode> > (otfn2));
    FunctionDefaults::tree->setTreeList(treeList);
}


/*
    template <typename T>
    class MulNodeInfo {
    public:
        const Tensor<T>* t;
        Level n;
        Translation lx, ly, lz;
        bool status;

        MulNodeInfo()
            : t(0),n(0),lx(0),ly(0),lz(0),status(false) {}

        void set(const Tensor<T>* t, Level n,
                 Translation lx, Translation ly, Translation lz) {
            this->t = t;
            this->n = n;
            this->lx = lx;
            this->ly = ly;
            this->lz = lz;
            status = true;
        template <typename T>
        class MulNodeInfo {
        public:
            const Tensor<T>* t;
            Level n;
            Translation lx, ly, lz;
            bool status;
     
            MulNodeInfo()
                : t(0),n(0),lx(0),ly(0),lz(0),status(false) {}
     
            void set(const Tensor<T>* t, Level n,
                     Translation lx, Translation ly, Translation lz) {
                this->t = t;
                this->n = n;
                this->lx = lx;
                this->ly = ly;
                this->lz = lz;
                status = true;
            };
     
            operator bool() {return status;};
     
            void send(Process rank);
     
            void recv(Process rank);
>>>>>>> .r80
        };
     
        /// At the quadrature points for box (n,l) evaluate the scaling functions (nn,ll)
        template <typename T>
        Tensor<double> Function<T>::mul_eval_sf(Level n, Translation l, Level nn, Translation ll) {
            int npt = data->cdata->npt;
            Tensor<double> phi(npt,k); // phi(i,j) = at  value of phi[j](x[i])
     
            Tensor<double>& quad_x = data->cdata->quad_x;
     
            double scale = 1.0/two_to_power(n);
            double fac = sqrt(double(two_to_power(nn)));
            if (n < nn) throw "mul_eval_sf: n < nn ?";
            double twonn = two_to_power(n-nn);
            double xlo = l - twonn*ll;
            for (int i=0; i<npt; i++) {
                double p[200];
                double x = scale*(xlo + quad_x(i));
                legendre_scaling_functions(x,k,p);
                for (int j=0; j<k; j++) {
                    phi(i,j) = phi[j]*fac
                }
            }
        }
     
        template <typename T>
        T Function<T>::_mul(Function<T>& afun, Function<T>& bfun,
                            Function<T>& cfun, OctTreeT* tree, 
                            MulNodeInfo<T>& ainfo, MulNodeInfo<T>& binfo) {
            cfun.set_active(tree);
     
            if (tree->isremote()) {
                if (tree->islocalsubtreeparent()) {
                    // If a function is locally labelled active, then the
                    // coefficients are somewhere below this parent node
                    // (perhaps remote).  If a function is inactive, then
                    // the coefficients must be above and we need to
                    // receive them.
                    if (!afun.isactive()) ainfo.recv(tree->rank());
                    if (!bfun.isactive()) binfo.recv(tree->rank());
                }
                else {
                    if (ainfo) ainfo.send(tree->rank());
                    if (binfo) binfo.send(tree->rank());
                    return;
                }
            }
     
            if (at) ainfo.set(at, tree->n(), tree->lx(), tree->ly(), tree->lz());
            if (bt) binfo.set(at, tree->n(), tree->lx(), tree->ly(), tree->lz());
            if (ainfo && binfo) {
                TensorT r(2*k,2*k,2*k);
                // All of the tensor constructors can be optimized away
                // with just a little work.
                FORIJKL(Level n = tree->n()+1;
                        Translation lx = tree->x()*2+i;
                        Translation ly = tree->y()*2+j;
                        Translation lz = tree->z()*2+k;
                        Tensor<double> aphix = mul_eval_sf(n,lx,a.n,a.lx);
                        Tensor<double> aphiy = mul_eval_sf(n,ly,a.n,a.ly);
                        Tensor<double> aphiz = mul_eval_sf(n,lz,a.n,a.lz);
                        Tensor<double> bphix = mul_eval_sf(n,lx,b.n,b.lx);
                        Tensor<double> bphiy = mul_eval_sf(n,ly,b.n,b.ly);
                        Tensor<double> bphiz = mul_eval_sf(n,lz,b.n,b.lz);
                        
                        TensorT aval = transform3d_3c(*ainfo.t,aphix,aphiy,aphiz);
                        TensorT bval = transform3d_3c(*binfo.t,bphix,bphiy,bphiz);
                        r(s[i],s[j],s[k]) = transform3d_inplace(aval.emul(bval),
                                                                data->cdata->quad_phiw,
                                                                data->cdata->work);
                        );
            }
            else {
                FOREACH_CHILD(OctTreeT, tree,
                              if (afun.isactive(child) || bfun.isactive(child)) {
                                  _mul(afun,bfun,cfun,child,ainfo,binfo);
                              });
            }
        }
    */
    
    
